---
layout: page
title: The War of The Learned
subtitle: Data-driven Linguistic Quality Analysis based on Reddit data
---

<img src="assets/reddit_posts/post_1.png" width="50%" >

<div class="section" style="border-top: 0px;">
    TLDR; [Maybe add a tldr, could emphasise that we are answering from a "user" per
    perspective. I'm not 100% convinced]
    <br><br>

    It's not the first time I've seen such sentiments around here. Actually,
    I find it super interesting, as such discussions about "linguistic quality" are not recent,
    in fact you can find them pretty much at any point 
    since we've begun to standardise our languages. Still, with the rise of 
    social media and instant messaging, such perceptions have been on the rise
    and it could be interesting to know if they are based on actual data. And
    if so, what motivates the difference of language quality between users.

    <br><br>

    [Should we add here the different research questions? Or do we keep
    the "comment based approach"? Or both?]

</div>

<div class="section">
    <h1>Dataset</h1>
    <div>
        <h2>Hyperlinks</h2>
        <div>
            [Introduce what our dataset is]
        </div>
        <h2>Embeddings</h2>
        <h3>Introduction</h3>
        <div>
            Along with the initial subreddit hyperlinks dataset, we used another dataset: 
            the embedding vectors of subreddits (available on the SNAP website).
        </div>
        <div>
            These embeddings are high-dimensional vectors (in our case, 300 dimensions). 
            They are designed to represent similarities between data points in a complex space. 
            Specifically, each of the ~50,000 subreddits is assigned a 300-dimensional vector. 
            These vectors indicate similarity based on user behavior: if many users post in 
            the same group of subreddits, those subreddits will be closer to each other in this 300-dimensional space.
        </div>
        <div>
            These embeddings are very useful for our research on linguistic quality and our goal to determine 
            'who speaks the best.' They allow us to identify clusters of subreddits where users share similar 
            interests, effectively grouping subreddits into distinct communities.
        </div>
        <h3>Weakness</h3>
        <div>
            The embeddings are really powerfull and shows real performances. 
            The problem of this dataset comes from reddit itself and the communtiies.
            Indeed, the communities 
        </div>
        
    </div>
</div>

<div class="section">
    <h1>What is language quality?</h1>
    The first thing we need to know when trying to understand language quality
    on reddit, is to actually define what language quality <em>is</em>. We could 
    define language quality of a text as "<b>the similarity between a text and
    a shared construction of the "perfect" language</b>. [do you agree? should i remove it?]
    However, we cannot apply directly such a definition to our data, we need to 
    find a way to operationalise such a concept. Thus, I decided to take an
    approach that combined both what our data provided and what different measures
    suggested that this "shared construction" is, arriving at the following metric:

    <div class="important_info">
        <ul>
            <li><b>Lexical Richness</b>: Ratio of unique words in a post</li>
            <li><b>Syntactic Complexity</b>: Average words per sentence</li>
            <li><b>Readability</b>: Automated Readability Index</li>
            <li><b>Cognitive Depth</b>: LIWC reasoning and complexity measures</li>
        </ul>
        [add justifications]
    </div>

    <div class="plot">
        <iframe 
            src="assets/plots/linguistic_feature_histogram.html"
            width="100%" 
            height="600px" 
            style="border:none;">
        </iframe>
    </div>
    [add only the features that we end up choosing, maybe more if interactive]
    <br>
    [Also, develop on the insights of these features]

    <img src="assets/plots/feature_correlation_matrix.png" width="70%">
    [we should refocus the plot on our current variables, and maybe
    add a interactive feature where we can explore other potential variables]

    <br><br>
    As you can see in this correlation matrix, our chosen features do not
    seem to overlap, showing that they each embody one aspect of Linguistic
    cognition and thus capture meaningful language patterns.

    <br><br>
    [We need to add more info, but depends on what features we end up choosing
    in the end]
</div>

<div class="section">
    <h1>2. Linguistic quality within a subreddit</h1>
    <div>
        [Add insights of posts within a specific subbreddit. ]
        <br><br>
        [Introduce the notion of linguistic_profile_score]
    </div>
</div>

<div class="section">
    <h1>3. Linguistic variation within a topic/community</h1>
    <img src="assets/reddit_posts/comment_1.png" width="50%">
    <div>
        Introduce cluster methodology
        <br><br>

        Apply profile score within a community + apply plots 5/6 + others?
        to see which subreddits come up on top and try to explain why
        by looking at what makes these subreddits score well.
        <br>
        For interactivity we can make it so that they can explore the different
        clusters we have
    </div>
</div>


<div class="section">
    <h1>4. Linguistic variation across all reddit</h1>
    <div>
        [Present top 10 / bottom 10 across the whole dataset + insights 
        from the feature comparison]

        <br><br>

        Depending on how robust the topic modeling is, we could aggregate
        results again to see if there is meaningful differences between
        the different topics in terms of linguistic profiles (so aggregate
        profile scores again) 

        <br><br>
        Subbredit clustering -> explain results
    </div>
</div>


<div class="section">
    <h1>5. Linguistic quality and negativity</h1>
    <div>
        [Linguistics features by post sentiment plot]

        <br><br>
        [Further analysis? Or should we include it directly in each
        section?]
    </div>
</div>

<div class="section">
    <h1>7. Conclusion</h1>
    <div>
        
    </div>
</div>

<div class="section">
    <h1>Structure [to be removed]</h1>
    <div>
        Story feature: Conversation between a reddit user seeking to understand language quality and ourselves,
        commenters to the post that do an analysis on language quality. Each section is introduced by OP asking a further question
        to our comment
        <br>
        <br>
        General structure
        <ul>
            <li>1. What is language quality?
                <ul>
                    <li>1.1 Explain what is linguistic quality</li>
                    <li>1.2 Introduce our dataset</li>
                    <li>1.3 Introduce metrics</li>
                    <li>1.4 Show metrics justification</li>
                </ul>
            </li>
            <li>2. Linguistic variation within a subreddit</li>
            <li>3. Linguistic variation within a topic/community</li>
            <li>4. Linguistic variation between different topics/communities</li>
            <li>5. Linguistic quality and negativity</li>
            <li>7. Conclusion</li>
                <ul>Why focus on language quality?</ul>
        </ul> 
    </div>
    <div class="important_info">
        <h3>Research Questions:</h3>
        <ol>
            <li>RQ1</li>
            <li>RQ2</li>
        </ol>
    </div>
    <br>
    <div class="important_info">
        Add any relevant important information or key finding that needs to be highlighted
    </div>
</div>




