---
layout: page
title: The War of The Learned
subtitle: Data-driven Linguistic Quality Analysis based on Reddit data
---

<!-- ======================================================= -->
<!-- GLOBAL STYLING SYSTEM                                   -->
<!-- Change --theme-color here to update the whole page      -->
<!-- ======================================================= -->
<style>
    :root {
        /* CORE THEME COLORS */
        --theme-color: #0143f8;       /* The main Deep Blue */
        --theme-light: #e6edff;       /* Very light blue for backgrounds */
        --theme-accent: #f57f17;      /* Orange for alerts/todos */
        
        /* TEXT & LAYOUT */
        --text-main: #333333;
        --text-muted: #555555;
        --border-radius: 8px;
        --spacing-section: 60px;
        --spacing-item: 30px;
    }

    /* --- LAYOUT UTILITIES --- */
    .ds-section {
        margin-bottom: var(--spacing-section);
        padding-top: 30px;
        border-top: 1px solid #eee;
        color: var(--text-main);
        line-height: 1.6;
    }
    .ds-section:first-of-type { border-top: none; padding-top: 0; }

    .ds-grid-2 {
        display: grid;
        grid-template-columns: 1fr 1fr;
        gap: var(--spacing-item);
        margin: var(--spacing-item) 0;
    }

    .ds-flex-row {
        display: flex;
        gap: var(--spacing-item);
        align-items: flex-start;
        margin: var(--spacing-item) 0;
    }

    /* --- VISUAL COMPONENTS (FIXED) --- */
    
    /* 1. Plot Frames */
    .ds-frame {
        width: 100%;
        /* Only the thin outer line is blue */
        border: 2px solid var(--theme-color); 
        border-radius: var(--border-radius);
        /* Background is white so images/plots sit on clean canvas */
        background: white; 
        overflow: hidden;
        margin-bottom: 10px;
        box-shadow: 0 4px 10px rgba(0,0,0,0.1);
        /* Flex centers content, but prevents "stretching" weirdness */
        display: flex;
        align-items: center;
        justify-content: center;
        box-sizing: border-box;
    }
    
    .ds-caption {
        font-size: 0.9em;
        font-style: italic;
        color: var(--text-muted);
        text-align: center;
        margin-top: 5px;
        display: block;
    }

    /* 2. Images */
    .ds-img-responsive {
        max-width: 100%;
        max-height: 100%; /* Prevents vertical overflow */
        height: auto;
        object-fit: contain;
    }
    .ds-img-main {
        display: block;
        margin: 0 auto var(--spacing-item) auto;
        max-width: 60%; /* Or 50% as you had before */
        border-radius: var(--border-radius);
        
        /* The Shadow Effect */
        box-shadow: 0 10px 30px rgba(0,0,0,0.15); 
        border: 1px solid rgba(0,0,0,0.05); /* Subtle border for definition */
    }

    /* 4. Lists & Clusters */
    .ds-list-box {
        background: #f8f9fa;
        padding: 20px;
        border-radius: var(--border-radius);
        border-left: 5px solid var(--theme-color);
        /* CRITICAL FIX: Prevents border from stretching to match neighbor's height */
        height: fit-content; 
        box-sizing: border-box;
    }

    /* 5. TODO / Placeholder Boxes */
    .ds-todo {
        background-color: #fff9c4;
        border: 1px dashed var(--theme-accent);
        color: #444;
        padding: 15px;
        margin: 20px 0;
        font-family: monospace;
        font-size: 0.85em;
    }
    .ds-todo-label { font-weight: bold; color: #e65100; display: block; margin-bottom: 5px; }

    /* 6. Scoped styles for the metric accordion */
    .metric-accordion {
        display: flex;
        flex-direction: column;
        gap: 10px;
        margin-top: 15px;
        font-family: sans-serif; /* Ensure readable font */
    }

    .metric-item {
        background-color: rgba(255, 255, 255, 0.5);
        border: 1px solid #ccc;
        border-radius: 8px;
        overflow: hidden;
        transition: all 0.3s ease;
    }

    .metric-header {
        display: flex;
        justify-content: space-between;
        align-items: center;
        padding: 15px;
        cursor: pointer;
        background-color: rgba(0, 0, 0, 0.03);
    }

    .metric-header:hover {
        background-color: rgba(0, 0, 0, 0.07);
    }

    .metric-title-group {
        display: flex;
        flex-direction: column;
    }

    .metric-name {
        font-weight: bold;
        font-size: 1.1em;
        color: #0143f8; /* Matching your blue theme */
    }

    .metric-short {
        font-size: 0.9em;
        color: #555;
        font-style: italic;
    }

    .metric-arrow {
        font-size: 1.2em;
        transition: transform 0.3s ease;
        color: #0143f8;
    }

    .metric-item.active .metric-arrow {
        transform: rotate(180deg);
    }

    .metric-content {
        max-height: 0;
        overflow: hidden;
        transition: max-height 0.3s ease-out;
        padding: 0 15px;
        background-color: white;
    }

    .metric-content-inner {
        padding: 15px 0;
        font-size: 0.95em;
        line-height: 1.6;
        color: #333;
    }

    .metric-formula {
        background-color: #f4f4f4;
        padding: 5px 10px;
        border-radius: 4px;
        font-family: monospace;
        font-size: 0.85em;
        display: inline-block;
        margin-bottom: 10px;
        border: 1px solid #ddd;
        color: #d63384; /* Code pink/red color */
    }

    .metric-label {
        font-weight: bold;
        margin-right: 5px;
    }

    .accordion {
        /* The Dark Blue Left Border */
        border-left: 6px solid #0b1e47; 
        
        /* Box styling */
        background-color: #f8f9fa;
        padding: 20px;
        margin: 25px 0;
        border-radius: 0 8px 8px 0; /* Round only the right corners */
        box-shadow: 0 4px 6px rgba(0,0,0,0.05);
        font-family: sans-serif;
    }

    /* RESPONSIVE */
    @media (max-width: 768px) {
        .ds-grid-2, .ds-flex-row { grid-template-columns: 1fr; flex-direction: column; }
        .ds-img-main { max-width: 100%; }
    }
</style>

<!-- ======================================================= -->
<!-- CONTENT START                                           -->
<!-- ======================================================= -->

<img src="assets/reddit_posts/post_1.png" class="ds-img-main">

<!-- SECTION: INTRO -->
<div class="ds-section">
    <div class="ds-todo">
        <span class="ds-todo-label">PLACEHOLDER: TLDR</span>
        TLDR; [Maybe add a tldr, could emphasise that we are answering from a "user" perspective.]
    </div>

    <p>
        It's not the first time I've seen such sentiments around here. Actually,
        I find it super interesting, as such discussions about "linguistic quality" are not recent,
        in fact you can find them pretty much at any point since we've begun to standardise our languages. 
        Still, with the rise of social media and instant messaging, such perceptions have been on the rise
        and it could be interesting to know if they are based on actual data. And
        if so, what motivates the difference of language quality between users.
    </p>

    <div class="ds-todo">
        [Should we add here the different research questions? Or do we keep the "comment based approach"? Or both?]
    </div>
</div>

<!-- SECTION: DATASET -->
<div class="ds-section">
    <h1>1. Dataset</h1>
    
    <h2>Hyperlinks</h2>
    <div class="ds-todo">[Introduce what our dataset is]</div>

    <h2>Embeddings</h2>
    
    <h3>Introduction</h3>
    <p>
        Along with the initial subreddit hyperlinks dataset, we used another dataset: 
        the embedding vectors of subreddits (available on the SNAP website).
        These embeddings are high-dimensional vectors (in our case, 300 dimensions). 
        They are designed to represent similarities between data points in a complex space. 
    </p>
    <p>
        These vectors indicate similarity based on user behavior: if many users post in 
        the same group of subreddits, those subreddits will be closer to each other in this
        300-dimensional space. They allow us to identify clusters of subreddits where users share similar 
        interests, effectively grouping subreddits into distinct communities.
    </p>
    
    <h3>Weakness</h3>
    <p>
        While these embeddings are powerful and perform well, the dataset faces challenges due to the
        nature of Reddit communities and the high number of data.
    </p>
    
    <div class="ds-blockquote">
        "One might assume that a dataset of 50,000 subreddits is relatively small. However, each 
        entry is a 300-dimensional vector... Calculating the similarity between every possible pair 
        of subreddits is a computationally intensive task...
        To overcome this, we implemented a batch processing approach."
    </div>

    <p>
        Indeed communities are not perfectly separated into 'clean' clusters. Most users have diverse interests 
        and post in a wide variety of subreddits. This creates a significant amount of overlap between vectors, 
        creating 'noisy' links and blurring the boundaries between different communities.
    </p>

    <h3>Visualizing the Embedding Weaknesses</h3> 
    <p>
        The following graphs illustrate the weakness mentioned previously.
        On <b>fig 1</b>, a 2D projection shows vectors forming a large, dense circle with significant overlap.
        On <b>fig 2</b>, the distribution reveals a non-negligible number of subreddits that have more than 10,000 neighbors with over 80% similarity.
    </p>

    <!-- PLOT 1 -->
    <div style="margin-bottom: 40px;">
        <div class="ds-frame" style="height: 600px;">
            <iframe src="assets/plots/embeddings_and_clustering/reddit_map.html" width="100%" height="100%" style="border:none;"></iframe>
        </div>
        <span class="ds-caption">Figure 1: 2D Projection of Subreddits</span>
    </div>

    <!-- PLOT 2 -->
    <div style="margin-bottom: 40px;">
        <div class="ds-frame" style="height: 500px;">
            <img src="assets/plots/embeddings_and_clustering/distribution_of_closed_neigbors_embeddings.png" class="ds-img-responsive">
        </div>
        <span class="ds-caption">Figure 2: Distribution of Close Neighbors</span>
    </div>
</div>

<!-- SECTION: DEFINING LANGUAGE -->
<div class="ds-section">
    <h1>2. What is language quality?</h1>
    <p>
        The first thing we need to know when trying to understand language quality
        on reddit, is to actually define what language quality <em>is</em>. We needed to 
        find a way to operationalise such a concept. Thus, I decided to take an
        approach that combined both what our data provided and what different measures
        suggested that this "shared construction" is, arriving at the following metrics:
    </p>

    <!-- INLINE ACCORDION (Updated to use global CSS variables) -->

    <!-- START: Metric Accordion Component -->
    <div class="accordion">
        <p>To calculate the <b>Linguistic Quality Index (LQI)</b>, we aggregated four robust dimensions. Click below to see the exact formulas derived from our data processing.</p>
        
        <div class="metric-accordion">
            
            <!-- Metric 1: Lexical Richness (Updated to Herdan's C) -->
            <div class="metric-item">
                <div class="metric-header" onclick="toggleMetric(this)">
                    <div class="metric-title-group">
                        <span class="metric-name">Lexical Richness</span>
                        <span class="metric-short">Robust vocabulary diversity (Herdan's C).</span>
                    </div>
                    <span class="metric-arrow">▼</span>
                </div>
                <div class="metric-content">
                    <div class="metric-content-inner">
                        <div class="metric-formula">log(Unique Words) / log(Total Words)</div>
                        <p><span class="metric-label">Justification:</span> Standard Type-Token Ratio (Unique/Total) is biased against long texts. We used Herdan's C (Log-TTR) to ensure fair comparison between short comments and long rants.</p>
                        <p><span class="metric-label">Why it matters:</span> It distinguishes between users who repeat the same keywords ("spam/circlejerk") and users who employ a varied, precise vocabulary.</p>
                    </div>
                </div>
            </div>

            <!-- Metric 2: Structural Complexity (Updated) -->
            <div class="metric-item">
                <div class="metric-header" onclick="toggleMetric(this)">
                    <div class="metric-title-group">
                        <span class="metric-name">Structural Complexity</span>
                        <span class="metric-short">A balance of word length and sentence construction.</span>
                    </div>
                    <span class="metric-arrow">▼</span>
                </div>
                <div class="metric-content">
                    <div class="metric-content-inner">
                        <div class="metric-formula">(0.5 * Avg Word Len) + log(Avg Sentence Len)</div>
                        <p><span class="metric-label">Justification:</span> Simple sentence length is noisy (a 50-word list of groceries is not "complex"). We created a composite score that rewards using longer, more complex words <i>within</i> structurally longer sentences.</p>
                        <p><span class="metric-label">Why it matters:</span> This identifies "Elaborated Code"—language used to construct detailed arguments rather than quick, reactive firing.</p>
                    </div>
                </div>
            </div>

            <!-- Metric 3: Formality Index (New) -->
            <div class="metric-item">
                <div class="metric-header" onclick="toggleMetric(this)">
                    <div class="metric-title-group">
                        <span class="metric-name">Formality Index</span>
                        <span class="metric-short">Objectivity vs. Subjectivity (Contextuality).</span>
                    </div>
                    <span class="metric-arrow">▼</span>
                </div>
                <div class="metric-content">
                    <div class="metric-content-inner">
                        <div class="metric-formula">Articles - Pronouns - (2 * Swearing) - Uppercase</div>
                        <p><span class="metric-label">Justification:</span> Based on Heylighen & Dewaele (2002). 
                        <br>• <b>(+) Articles (The/A):</b> Indicate noun-heavy, objective descriptions.
                        <br>• <b>(-) Pronouns (I/You):</b> Indicate subjective, chatty interaction.
                        <br>• <b>(-) Swearing/Caps:</b> Heavily penalized markers of impulsivity.</p>
                        <p><span class="metric-label">Why it matters:</span> It separates "Contextual" language (casual, face-to-face style) from "Formal" language (academic/professional style).</p>
                    </div>
                </div>
            </div>

            <!-- Metric 4: Cognitive Depth (Same) -->
            <div class="metric-item">
                <div class="metric-header" onclick="toggleMetric(this)">
                    <div class="metric-title-group">
                        <span class="metric-name">Cognitive Depth</span>
                        <span class="metric-short">The presence of active reasoning.</span>
                    </div>
                    <span class="metric-arrow">▼</span>
                </div>
                <div class="metric-content">
                    <div class="metric-content-inner">
                        <div class="metric-formula">Mean(LIWC_CogMech + LIWC_Insight + LIWC_Cause)</div>
                        <p><span class="metric-label">Justification:</span> We aggregate LIWC categories that track words related to processing information (<i>think, know</i>) and causality (<i>because, hence, effect</i>).</p>
                        <p><span class="metric-label">Why it matters:</span> This distinguishes between descriptive storytelling or emotional venting and analytical reasoning.</p>
                    </div>
                </div>
            </div>

        </div>
    </div>

    <script>
        function toggleMetric(element) {
            // Toggle the active class on the parent item
            const item = element.parentElement;
            item.classList.toggle('active');

            // Handle the max-height for the slide effect
            const content = item.querySelector('.metric-content');
            if (content.style.maxHeight) {
                content.style.maxHeight = null;
            } else {
                content.style.maxHeight = content.scrollHeight + "px";
            }
        }
    </script>
    <!-- END: Metric Accordion Component -->


    <div class="ds-frame" style="height: 600px;">
        <iframe src="assets/plots/linguistic_feature_histogram.html" width="100%" height="100%" style="border:none;"></iframe>
    </div>
    
    <div class="ds-todo">
        [add only the features that we end up choosing]
        [Develop on the insights of these features]
    </div>

    <img src="assets/plots/feature_correlation_matrix.png" class="ds-img-responsive" style="max-width: 70%; margin: 20px auto; display:block;">
    
    <p>
        As you can see in this correlation matrix, our chosen features do not
        seem to overlap, showing that they each embody one aspect of linguistic
        cognition and thus capture meaningful language patterns.
    </p>
</div>

<!-- SECTION: SUBREDDIT QUALITY -->
<div class="ds-section">
    <h1>3. Linguistic quality within specific subreddits</h1>
    
    <div class="ds-frame" style="height: 600px;">
        <iframe 
            src="assets/plots/metric_distributions.html" 
            style="width: 100%; height: 100%; border: none;"
            title="Metric Distributions">
        </iframe>
    </div>
    <span class="ds-caption">Comparison of metrics distribution of best and worst subs with at least 500 posts</span>
    
    <div style="margin-top: 20px;">
        <p><b>Interesting observations:</b></p>
        <p>First, most of the clusters are dense and well-separated, which successfully achieves our goal of clear topic categorization.</p>
    </div>
    
    <div class="ds-todo">
        [Add insights of posts within a specific subbreddit.]
        [Introduce the notion of linguistic_profile_score]
    </div>
</div>

<!-- SECTION: CLUSTERING / COMMUNITY -->
<div class="ds-section">
    <h1>4. Linguistic variation within a topic/community</h1>
    <img src="assets/reddit_posts/comment_1.png" class="ds-img-main" style="width: 50%;">

    <h2>Introduction</h2>
    <p>
        What is a community? Oxford Languages defines it as: 'a group of people 
        living in the same place or having a particular characteristic in common.'
        Applying this to Reddit, we aim to group subreddits with similar vector representations 
        into distinct clusters, effectively mapping out digital communities based on shared user interests.
    </p>

    <h2>Methodology</h2>
    <h3>Clustering Strategy and Challenges</h3>
    
    <p>
        The primary challenge in this analysis stems from <strong>"bridges"</strong>: 
        subreddits frequented by users from vastly different backgrounds. These bridges 
        exhibit a high number of neighbors, making them notoriously difficult to classify.
    </p>

    <div class="ds-list-box" style="margin-bottom: 20px;">
        <div class="ds-list-clean">
            <ul>
                <li><strong>Why K-means Failed:</strong> It forces high-dimensional "clouds" into rigid spheres.</li>
                <li><strong>HDBSCAN Limitations:</strong> Too selective, labeling too much data as noise.</li>
                <li><strong>Solution:</strong> A network-based approach (k-NN graph + Leiden algorithm) to uncover latent structures.</li>
            </ul>
        </div>
    </div>

    <p>To refine the methodology, three key improvements were implemented:</p>
    <ol>
        <li><strong>Scope Restriction:</strong> Clustering performed exclusively on subreddits in our dataset.</li>
        <li><strong>Recursive Refinement:</strong> Noisy groups were re-processed (2nd pass).</li>
        <li><strong>Representative Sampling:</strong> Only the 250 subreddits closest to each cluster's centroid were retained.</li>
    </ol> 

    <p>These steps significantly reduced noise and computational load, resulting in 36 high-cohesion clusters.</p>

    <h4>Results (Pass 1)</h4>   
    <div class="ds-grid-2">
        <div>
            <div class="ds-frame" style="height: 300px;">
                <img src="assets/plots/embeddings_and_clustering/1st_clustering_box_no_filter.png" class="ds-img-responsive">
            </div>
            <span class="ds-caption">Distribution before filtering (High Noise)</span>
        </div>
        <div>
            <div class="ds-frame" style="height: 300px;">
                <img src="assets/plots/embeddings_and_clustering/1st_clustering_box_with_filter.png" class="ds-img-responsive">
            </div>
            <span class="ds-caption">Distribution after keeping 250 best subs (Clean)</span>
        </div>
    </div>

    <p>
        The second plot demonstrates a clear improvement following the distance-based pruning. 
        We achieved a substantial noise reduction, with most distances falling below a 0.5 threshold.
    </p>

    <!-- Cluster Lists Grid -->
    <div class="ds-grid-2">
        <!-- List of Clusters -->
        <div class="ds-list-box">
            <h4>Relevant clusters and assigned label</h4>
            <div class="ds-list-clean">
                <ul>
                    <li><strong>2:</strong> Gaming / PC</li>
                    <li><strong>4:</strong> Popular / Memes</li>
                    <li><strong>6:</strong> Webmarketing / Dev</li>
                    <li><strong>7:</strong> Adult Content</li>
                    <li><strong>9:</strong> Music</li>
                    <li><strong>10:</strong> TV / Movies</li>
                    <li><strong>12:</strong> Feminine Celebrity</li>
                    <li><strong>13:</strong> Sports (US)</li>
                    <li><strong>14:</strong> Sports (Soccer)</li>
                    <li><strong>15:</strong> League of Legends</li>
                    <li><strong>16:</strong> Crypto / Blockchain</li>
                    <li><strong>17:</strong> Fiction / Art</li>
                    <li><strong>18:</strong> My Little Pony</li>
                    <li><strong>19:</strong> YouTube / Creators</li>
                    <li><strong>23:</strong> Japanese Subreddits</li>
                    <li><strong>24:</strong> K-Pop</li>
                    <li><strong>25:</strong> Metafandom</li>
                    <li><strong>26:</strong> Wrestling</li>
                    <li><strong>27:</strong> Retrogaming</li>
                    <li><strong>28:</strong> Vape</li>
                    <li><strong>29:</strong> Educational Video</li>
                </ul>   
            </div>
        </div>
        
        <!-- Examples -->
        <div class="ds-list-box" style="border-color: var(--text-muted);">
            <h4>Examples near centroid</h4>
            <div style="font-size: 0.9em; line-height: 1.6;">
                <p><strong>Cluster 2:</strong> oxygennotincluded, swgemu, speedrunnersgame, pokemmo, hollowknight...</p>
                <p><strong>Cluster 9:</strong> soothing, noise, music_share, selfmusic, underground_music, experimental...</p>
                <p><strong>Cluster 16:</strong> bitcoinuk, counterparty_xcp, trezor, augur, lisk, bitcoin_unlimited...</p>
            </div>
        </div>  
    </div>

    <p>Then we took all the subreddits from the remaining clusters and ran clustering again leading to these new clusters:</p>

    <!-- 2nd Pass Visualization -->
    <div class="ds-flex-row">
        <div style="flex: 2;">
            <div class="ds-frame" style="height: 400px;">
                <img src="assets/plots/embeddings_and_clustering/2nd_clustering_box_with_filter.png" class="ds-img-responsive">
            </div>
            <span class="ds-caption">Box plots of the clusters generated from noise (2nd Pass)</span>
        </div>

        <div class="ds-list-box" style="flex: 1;">
            <h4>New clusters found</h4>
            <div class="ds-list-clean">
                <ul>
                    <li><strong>100:</strong> R4R / Personals</li>
                    <li><strong>103:</strong> Politics / Academics</li>
                    <li><strong>107:</strong> Adult Content</li>
                    <li><strong>108:</strong> US States and Cities</li>
                    <li><strong>109:</strong> Radical Politics</li>
                    <li><strong>112:</strong> India</li>
                    <li><strong>113:</strong> Image Of</li>
                    <li><strong>114:</strong> Germany</li>
                    <li><strong>115:</strong> News Auto</li>
                    <li><strong>117:</strong> Sweden</li>
                    <li><strong>120:</strong> Russia</li>
                </ul>
            </div>
        </div>
    </div>

    <h2>Final community map</h2>
    <div class="ds-frame" style="height: 600px;">
        <iframe src="assets/plots/embeddings_and_clustering/reddit_community_map.html" width="100%" height="100%" style="border:none;"></iframe>
    </div>
    <span class="ds-caption">Final interactive community map (Click the legend to isolate communities)</span>

    <div style="margin-top: 30px;">
        <p><b>Interesting observations:</b></p>
        <p>
            First, most clusters are dense and well-separated. Second, outliers like <b>gamingnews</b> appearing in 
            "My Little Pony" are actually spatially located near "Retrogaming" on the map, proving the geometry works even if the label is odd.
            Third, "Adult Content" is intentionally grouped despite fragmentation to avoid granular categorization of fetishes.
        </p>
    </div>

    <div class="ds-todo">
        Introduce cluster methodology
        Apply profile score within a community + apply plots 5/6 + others?
    </div>
</div>

<!-- SECTION: VARIATION ACROSS REDDIT -->
<div class="ds-section">
    <h1>4. Linguistic variation across all reddit</h1>
    <div class="ds-todo">
        [Present top 10 / bottom 10 across the whole dataset + insights]
        <br>
        [Subbredit clustering -> explain results]
    </div>
</div>

<!-- SECTION: NEGATIVITY -->
<div class="ds-section">
    <h1>5. Linguistic quality and negativity</h1>
    <div class="ds-todo">
        [Linguistics features by post sentiment plot]
        <br>
        [Further analysis?]
    </div>
</div>

<!-- SECTION: CONCLUSION -->
<div class="ds-section">
    <h1>7. Conclusion</h1>
    <div class="ds-todo">
        TODO: Conclusion
    </div>
</div>

<!-- SECTION: STRUCTURE (Remove later) -->
<div class="ds-section" style="background-color: var(--theme-light); padding: 20px; border-radius: 8px;">
    <h1>Structure [to be removed]</h1>
    <div>
        Story feature: Conversation between a reddit user seeking to understand language quality and ourselves.
        <br><br>
        <strong>Research Questions:</strong>
        <ol>
            <li>RQ1</li>
            <li>RQ2</li>
        </ol>
    </div>
</div>