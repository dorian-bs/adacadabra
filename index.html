---
layout: page
title: The War of The Learned
subtitle: Data-driven Linguistic Quality Analysis based on Reddit data
---

<img src="assets/reddit_posts/post_1.png" width="50%" >

<div class="section" style="border-top: 0px;">
    TLDR; [Maybe add a tldr, could emphasise that we are answering from a "user" per
    perspective. I'm not 100% convinced]
    <br><br>

    It's not the first time I've seen such sentiments around here. Actually,
    I find it super interesting, as such discussions about "linguistic quality" are not recent,
    in fact you can find them pretty much at any point 
    since we've begun to standardise our languages. Still, with the rise of 
    social media and instant messaging, such perceptions have been on the rise
    and it could be interesting to know if they are based on actual data. And
    if so, what motivates the difference of language quality between users.

    <br><br>

    [Should we add here the different research questions? Or do we keep
    the "comment based approach"? Or both?]

</div>

<div class="section">
    <h1>Dataset</h1>
    <div>
        <h2>Hyperlinks</h2>
        <div>
            [Introduce what our dataset is]
        </div>

        <h2>Embeddings</h2>
        
        <h3>Introduction</h3>
        <div>
            Along with the initial subreddit hyperlinks dataset, we used another dataset: 
            the embedding vectors of subreddits (available on the SNAP website).
            <br><br>
            These embeddings are high-dimensional vectors (in our case, 300 dimensions). 
            They are designed to represent similarities between data points in a complex space. 
            Specifically, each of the ~50,000 subreddits is assigned a 300-dimensional vector. 
            These vectors indicate similarity based on user behavior: if many users post in 
            the same group of subreddits, those subreddits will be closer to each other in this
            300-dimensional space.
            <br><br>
            These embeddings are very useful for our research on linguistic quality and our goal to determine 
            'who speaks the best.' They allow us to identify clusters of subreddits where users share similar 
            interests, effectively grouping subreddits into distinct communities.
        </div>
        
        <h3>Weakness</h3>
        <div>
            While these embeddings are powerful and perform well, the dataset faces challenges due to the
            nature of Reddit communities and the high number of data.
            <br><br>
            "One might assume that a dataset of 50,000 subreddits is relatively small. However, each 
            entry is a 300-dimensional vector, and determining similarity requires computing a pairwise 
            distance matrix. Calculating the similarity between every possible pair of subreddits is a computationally 
            intensive task; a full matrix for 50,000 subreddits would require approximately 20GB of RAM, exceeding the capacity 
            of most standard machines and leading to system crashes.
            <br><br>
            To overcome this technical hurdle, we implemented a batch processing approach. By performing 
            calculations in blocks, we efficiently managed memory usage without compromising the integrity 
            of the results. While this hardware limitation was easy to solve, the more significant challenge remains 
            the inherent 'noise' and overlap within the nature of Reddit communities themselves."
            <br><br>
            Indeed communities are not perfectly separated into 'clean' clusters where we can easily say: 
            'These users are only interested in politics.' Most users have diverse interests and post in a wide
            variety of subreddits. This creates a significant amount of overlap between vectors. Consequently, 
            some subreddits appear very close to many others in the 300-dimensional space, which can create 'noisy' 
            links and blur the boundaries between different communities.
        </div>

        <h3>Visualizing the Embedding Weaknesses</h3> 
        <div>
            The following graphs illustrate the weakness mentioned previously.
            <br><br>
            On fig 1, a 2D projection (using dimensionality reduction) of the 50,000 subreddits shows the vectors 
            forming a large, dense circle with significant overlap. This visualization confirms that many communities
            are not clearly separated.
            <br><br>
            On fig 2, the graph displays the distribution of close neighbors (subreddits with a cosine similarity > 0.8).
            Cosine similarity measures the orientation of two vectors in the 300-dimensional space, ranging from -1 (opposite)
            to 1 (identical). The distribution reveals a non-negligible number of subreddits that have more than 10,000 neighbors 
            with over 80% similarity.
        </div>
   
        <div style="display: flex; flex-direction: column; gap: 40px; margin: 30px 0;">

        <div style="display: flex; flex-direction: column; align-items: center;">
            <div style="width: 100%; height: 600px; border: 2px solid #0143f8; border-radius: 8px; overflow: hidden; background: #0143f8;">
                <iframe 
                    src="assets/plots/embeddings_and_clustering/reddit_map.html" 
                    style="width: 100%; height: 100%; border: none;">
                </iframe>
            </div>
            <p style="margin-top: 10px; font-size: 0.9em;"><i>Figure 1: 2D Projection of Subreddits</i></p>
        </div>

        <div style="display: flex; flex-direction: column; align-items: center;">
            <div style="width: 100%; height: 500px; border: 2px solid #0143f8; border-radius: 8px; overflow: hidden; background: #0143f8; display: flex; align-items: center; justify-content: center;">
                <img 
                    src="assets/plots/embeddings_and_clustering/distribution_of_closed_neigbors_embeddings.png" 
                    alt="Distribution" 
                    style="max-width: 100%; max-height: 100%; object-fit: contain;">
            </div>
            <p style="margin-top: 10px; font-size: 0.9em;"><i>Figure 2: Distribution of Close Neighbors</i></p>
        </div>

</div>

</div>
        
    </div>
</div>

<div class="section">
    <h1>What is language quality?</h1>
    The first thing we need to know when trying to understand language quality
    on reddit, is to actually define what language quality <em>is</em>. We could 
    define language quality of a text as "<b>the similarity between a text and
    a shared construction of the "perfect" language</b>. [do you agree? should i remove it?]
    However, we cannot apply directly such a definition to our data, we need to 
    find a way to operationalise such a concept. Thus, I decided to take an
    approach that combined both what our data provided and what different measures
    suggested that this "shared construction" is, arriving at the following metric:

    <div class="important_info">
        <ul>
            <li><b>Lexical Richness</b>: Ratio of unique words in a post</li>
            <li><b>Syntactic Complexity</b>: Average words per sentence</li>
            <li><b>Readability</b>: Automated Readability Index</li>
            <li><b>Cognitive Depth</b>: LIWC reasoning and complexity measures</li>
        </ul>
        [add justifications]
    </div>

    <div class="plot">
        <iframe 
            src="assets/plots/linguistic_feature_histogram.html"
            width="100%" 
            height="600px" 
            style="border:none;">
        </iframe>
    </div>
    [add only the features that we end up choosing, maybe more if interactive]
    <br>
    [Also, develop on the insights of these features]

    <img src="assets/plots/feature_correlation_matrix.png" width="70%">
    [we should refocus the plot on our current variables, and maybe
    add a interactive feature where we can explore other potential variables]

    <br><br>
    As you can see in this correlation matrix, our chosen features do not
    seem to overlap, showing that they each embody one aspect of Linguistic
    cognition and thus capture meaningful language patterns.

    <br><br>
    [We need to add more info, but depends on what features we end up choosing
    in the end]
</div>

<div class="section">
    <h1>2. Linguistic quality within a subreddit</h1>
    <div>
        [Add insights of posts within a specific subbreddit. ]
        <br><br>
        [Introduce the notion of linguistic_profile_score]
    </div>
</div>

<div class="section">
    <h1>3. Linguistic variation within a topic/community</h1>
    <img src="assets/reddit_posts/comment_1.png" width="50%">

    <h2> Introduction </h2>
    <div>
        What is a community? Oxford Languages defines it as: 'a group of people 
        living in the same place or having a particular characteristic in common.'
        Applying this to Reddit, we can define a community as a group of users sharing a 
        common interest. In this section, our objective is to apply clustering algorithms
        to the subreddit embeddings. By doing so, we aim to group subreddits with similar 
        vector representations into distinct clusters, effectively mapping out digital communities 
        based on shared user interests.
    </div>

    <h2> Methodology </h2>
    <h3>Clustering Strategy and Challenges</h3>
    
    <div>
        <p>
            The primary challenge in this analysis stems from <strong>"bridges"</strong>: 
            subreddits frequented by users from vastly different backgrounds. These bridges 
            exhibit a high number of neighbors, making them notoriously difficult to classify. 
            In standard clustering, these points either force the creation of massive, noisy clusters 
            (K-means) or are discarded entirely as outliers (HDBSCAN).
        </p>

        <h4>Why K-means Failed</h4>
        <p>
            Our initial attempt using <strong>K-means</strong> proved inadequate. 
            K-means inherently assumes spherical (circular) cluster shapes and requires 
            <i>a-priori</i> knowledge of the exact number of clusters ($k$). Given the nature of 
            Reddit, communities are not perfectly circular; they overlap extensively due to the diverse 
            interests of users. Forcing these high-dimensional "clouds" into rigid spheres resulted 
            in a poor representation of the social reality.
        </p>

        <h4>The Density Limitation of HDBSCAN</h4>
        <p>
            <strong>HDBSCAN</strong> was a logical next step due to its ability to handle 
            non-spherical shapes. However, it proved too selective for our dataset. 
            While it identified high-density cores, the resulting clusters were too 
            small, and a significant portion of the subreddits were labeled as outliers. 
        </p>
        <p>
            At this stage, we realized our fundamental assumption was flawed: we were 
            looking for <strong>predefined topics</strong> (e.g., "politics", "video games"). 
            In reality, embeddings capture <strong>community behaviors</strong>. A cluster 
            might not represent a single subject, but rather a specific demographic of 
            users who share multiple interests.
        </p>

        <h4>Transition to a Network-Based Approach</h4>
        <p>
            This led us to test a third methodology. By moving away from purely 
            density-based approaches (which struggle with the uniform density of the 
            "bulky circle"), we aimed for an algorithm capable of detecting community 
            structures within the noise. While initial results 
            were promising, many subreddits still fell into irrelevant clusters. 
            To refine the methodology, three key improvements were implemented:
            <ul>
                <li><strong>1. Scope Restriction:</strong> The clustering was performed exclusively on subreddits belonging to the original dataset.</li>
                <li><strong>2. Recursive Refinement:</strong> Clusters were manually reviewed, and noisy groups were re-processed to achieve finer granularity.</li>
                <li><strong>3. Representative Sampling:</strong> Only the 250 subreddits closest to each cluster's centroid were retained to ensure community cohesion.</li>
            </ul> 
        </p>
        <p> <strong>The first improvement</strong> significantly enhanced overall results while reducing 
            the computational load (RAM usage). By filtering out unnecessary data, the number of active 
            subreddits was reduced from ~50,000 to approximately 17,000. </p>

        <p> <strong>The second improvement</strong> expanded the diversity of identified groups. 
            By performing a second clustering pass on the previously discarded "noise," we successfully 
            identified 13 additional communities, bringing the total to 36 relevant clusters. </p>

        <p> <strong>The third improvement</strong> ensured higher community consistency. Given that 
            the embeddings were dense and spread out, large clusters naturally accumulated noise. 
            To counter this, we focused on the "core" of each community: by retaining only the subreddits 
            closest to the centroids, we preserved the most representative samples. Ultimately, the final 
            dataset consists of 6,562 subreddits distributed across 36 high-cohesion clusters. </p>
            </div>

    
    





    <div>
        Introduce cluster methodology
        <br><br>

        Apply profile score within a community + apply plots 5/6 + others?
        to see which subreddits come up on top and try to explain why
        by looking at what makes these subreddits score well.
        <br>
        For interactivity we can make it so that they can explore the different
        clusters we have
    </div>
</div>


<div class="section">
    <h1>4. Linguistic variation across all reddit</h1>
    <div>
        [Present top 10 / bottom 10 across the whole dataset + insights 
        from the feature comparison]

        <br><br>

        Depending on how robust the topic modeling is, we could aggregate
        results again to see if there is meaningful differences between
        the different topics in terms of linguistic profiles (so aggregate
        profile scores again) 

        <br><br>
        Subbredit clustering -> explain results
    </div>
</div>


<div class="section">
    <h1>5. Linguistic quality and negativity</h1>
    <div>
        [Linguistics features by post sentiment plot]

        <br><br>
        [Further analysis? Or should we include it directly in each
        section?]
    </div>
</div>

<div class="section">
    <h1>7. Conclusion</h1>
    <div>
        
    </div>
</div>

<div class="section">
    <h1>Structure [to be removed]</h1>
    <div>
        Story feature: Conversation between a reddit user seeking to understand language quality and ourselves,
        commenters to the post that do an analysis on language quality. Each section is introduced by OP asking a further question
        to our comment
        <br>
        <br>
        General structure
        <ul>
            <li>1. What is language quality?
                <ul>
                    <li>1.1 Explain what is linguistic quality</li>
                    <li>1.2 Introduce our dataset</li>
                    <li>1.3 Introduce metrics</li>
                    <li>1.4 Show metrics justification</li>
                </ul>
            </li>
            <li>2. Linguistic variation within a subreddit</li>
            <li>3. Linguistic variation within a topic/community</li>
            <li>4. Linguistic variation between different topics/communities</li>
            <li>5. Linguistic quality and negativity</li>
            <li>7. Conclusion</li>
                <ul>Why focus on language quality?</ul>
        </ul> 
    </div>
    <div class="important_info">
        <h3>Research Questions:</h3>
        <ol>
            <li>RQ1</li>
            <li>RQ2</li>
        </ol>
    </div>
    <br>
    <div class="important_info">
        Add any relevant important information or key finding that needs to be highlighted
    </div>
</div>




